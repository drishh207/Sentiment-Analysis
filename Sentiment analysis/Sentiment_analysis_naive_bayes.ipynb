{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment analysis naive bayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de3l5GEBczZ4",
        "outputId": "7e8bc9a4-9e48-453c-d8dd-a3aabe21cdab"
      },
      "source": [
        "#Importing libraries\r\n",
        "!pip install vaderSentiment\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import re\r\n",
        "import string\r\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 26.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 3.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 3.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 3.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjebwWsfgeWL",
        "outputId": "1681b190-c888-44a9-889f-4e7483aec15c"
      },
      "source": [
        "#loading set\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "import glob\r\n",
        "\r\n",
        "path = r'drive/MyDrive/Sentiment analysis/' # use your path\r\n",
        "all_files = glob.glob(path + \"/*.CSV\")\r\n",
        "#print(all_files)\r\n",
        "li = []\r\n",
        "\r\n",
        "for filename in all_files:\r\n",
        "    df = pd.read_csv(filename, usecols = ['text'], index_col=None, header=0, nrows = 8000,encoding = \"ISO-8859-1\")\r\n",
        "    li.append(df)\r\n",
        "\r\n",
        "\r\n",
        "df = pd.read_csv(\"drive/MyDrive/Sentiment analysis/covid19_tweets.csv\",usecols = ['text'],encoding = \"ISO-8859-1\",nrows = 178687)\r\n",
        "li.append(df)\r\n",
        "\r\n",
        "frame = pd.concat(li, axis=0, ignore_index=True)\r\n",
        "tweets = pd.DataFrame(frame)\r\n",
        "print(tweets)\r\n",
        "index = tweets.index\r\n",
        "noOfTweet = len(index)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "['drive/MyDrive/Sentiment analysis/2020-04-16 Coronavirus Tweets.CSV', 'drive/MyDrive/Sentiment analysis/2020-04-17 Coronavirus Tweets.CSV', 'drive/MyDrive/Sentiment analysis/2020-04-18 Coronavirus Tweets.CSV', 'drive/MyDrive/Sentiment analysis/2020-04-19 Coronavirus Tweets.CSV', 'drive/MyDrive/Sentiment analysis/2020-04-20 Coronavirus Tweets.CSV', 'drive/MyDrive/Sentiment analysis/2020-04-21 Coronavirus Tweets.CSV', 'drive/MyDrive/Sentiment analysis/2020-04-22 Coronavirus Tweets.CSV', 'drive/MyDrive/Sentiment analysis/2020-04-23 Coronavirus Tweets.CSV', 'drive/MyDrive/Sentiment analysis/2020-04-24 Coronavirus Tweets.CSV', 'drive/MyDrive/Sentiment analysis/2020-04-25 Coronavirus Tweets.CSV', 'drive/MyDrive/Sentiment analysis/2020-04-26 Coronavirus Tweets.CSV', 'drive/MyDrive/Sentiment analysis/2020-04-27 Coronavirus Tweets.CSV', 'drive/MyDrive/Sentiment analysis/2020-04-28 Coronavirus Tweets.CSV', 'drive/MyDrive/Sentiment analysis/2020-04-29 Coronavirus Tweets.CSV', 'drive/MyDrive/Sentiment analysis/2020-04-30 Coronavirus Tweets.CSV']\n",
            "                                                     text\n",
            "0       Para complementar la higiene de tus manos, el ...\n",
            "1       PWDs from Tahanang Walang Hagdan get aid amid ...\n",
            "2       #France à¹à¸à¹à¸£à¸±à¸à¸à¸§à¸²à¸¡à¸à¸¸à¸...\n",
            "3       Target ng Department of Health na magkaroon ng...\n",
            "4       La @SSalud_mx lanzÃ³ una nueva convocatoria es...\n",
            "...                                                   ...\n",
            "298682  In new test of #Cabinet loyalty, the Secretary...\n",
            "298683  ADD THIS FOR COVID-19 : Wash your mouth. The v...\n",
            "298684  @JenRoss4Scot @coleman83avfc #JennyHarries is ...\n",
            "298685  The #BraveofHeartFund at E4E Relief has alread...\n",
            "298686  AP: Is US great again or dystopian? GOP says b...\n",
            "\n",
            "[298687 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZoer_Flgul_",
        "outputId": "c865c641-cff8-4ff4-d357-e36334e6fdab"
      },
      "source": [
        "#cleaning the tweets\r\n",
        "def remove_pattern(input_txt, pattern):\r\n",
        "  r = re.findall(pattern, str(input_txt))\r\n",
        "  for i in r:\r\n",
        "    input_txt = re.sub(i, '', str(input_txt))        \r\n",
        "  return input_txt\r\n",
        "\r\n",
        "def clean_tweets(tweet):\r\n",
        "  #remove twitter Return handles (RT @xxx:)\r\n",
        "  tweet = np.vectorize(remove_pattern)(tweet, \"RT @[\\w]*:\")\r\n",
        "    \r\n",
        "  #remove twitter handles (@xxx)\r\n",
        "  tweet = np.vectorize(remove_pattern)(tweet, \"@[\\w]*\")\r\n",
        "    \r\n",
        "  #remove URL links (httpxxx)\r\n",
        "  tweet = np.vectorize(remove_pattern)(tweet, \"https?://[A-Za-z0-9./]*\")\r\n",
        "    \r\n",
        "  #remove special characters, numbers, punctuations (except for #)\r\n",
        "  tweet = np.core.defchararray.replace(tweet, \"[^a-zA-Z]\", \" \")\r\n",
        "    \r\n",
        "  return tweet\r\n",
        "\r\n",
        "df = clean_tweets(tweets)\r\n",
        "print(df[1:10])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['PWDs from Tahanang Walang Hagdan get aid amid #COVID19 lockdown ']\n",
            " ['#France à¹\\x84à¸\\x94à¹\\x89à¸£à¸±à¸\\x9aà¸\\x84à¸§à¸²à¸¡à¸\\x97à¸¸à¸\\x81à¸\\x82à¹\\x8cà¸\\x97à¸£à¸¡à¸²à¸\\x99à¸\\x88à¸²à¸\\x81 # à¸\\x8aà¸¸à¸\\x94à¸\\x81à¸²à¸£à¹\\x81à¸¢à¸\\x81à¸\\x95à¸±à¸§à¸\\x97à¸µà¹\\x88à¸\\x94à¹\\x89à¸\\xadà¸¢à¸\\x81à¸§à¹\\x88à¸²à¸\\x82à¸\\xadà¸\\x87à¸\\x88à¸µà¸\\x99à¸\\x8bà¸¶à¹\\x88à¸\\x87à¹\\x84à¸¡à¹\\x88à¹\\x80à¸\\x9eà¸µà¸¢à¸\\x87 à¹\\x81à¸\\x95à¹\\x88à¸ªà¸±à¹\\x89à¸\\x99 à¹\\x81à¸\\x95à¹\\x88à¸¢à¸±à¸\\x87à¸\\x9eà¸±à¸\\x87\\n#COVID #COVID19 #à¹\\x80à¸\\x88à¸²à¸°à¸\\x9bà¸£à¸°à¹\\x80à¸\\x94à¹\\x87à¸\\x99 #italia #à¹\\x82à¸\\x84à¸§à¸´à¸\\x9419 #à¹\\x80à¸£à¸²à¹\\x84à¸¡à¹\\x88à¸\\x97à¸´à¹\\x89à¸\\x87à¸\\x81à¸±à¸\\x99  #italy #à¹\\x82à¸\\x84à¸§à¸´à¸\\x94 #à¸£à¸±à¸\\x90à¸\\x9aà¸²à¸¥à¹\\x80à¸®à¸\\x87à¸\\x8bà¸§à¸¢ #coronavirus #à¸\\x96à¸²à¸¡à¸\\x95à¸£à¸\\x87à¹\\x86à¸\\x81à¸±à¸\\x9aà¸\\x88à¸\\xadà¸¡à¸\\x82à¸§à¸±à¸\\x8d #CoronavirusUSA #à¸\\xadà¸¢à¸²à¸\\x81à¹\\x83à¸«à¹\\x89à¹\\x80à¸«à¹\\x87à¸\\x99 #coronathailand']\n",
            " ['Target ng Department of Health na magkaroon ng 8,000 #COVID19 test kada araw. ']\n",
            " ['La  lanzÃ³ una nueva convocatoria especial para personal mÃ©dico especializado que estÃ© interesado en unirse a enfrentar la epidemia del #Covid19 en el paÃ\\xads, chÃ©cala aquÃ\\xad.  ']\n",
            " ['G20 agrees to debt relief for poorest countries amid pandemic #COVID19 ']\n",
            " ['â\\x80\\x9cTenemos 170 respiradores en Mar del Plataâ\\x80\\x9d \\n#cuarentena #COVID19 #EmergenciaSanitaria \\n#QuedateEnCasa \\n ']\n",
            " ['B.C. health officials are urging people to kind and not jump to conclusions about travellers amid the #COVID19 pandemic. #Shuswap #kamloops  ']\n",
            " ['Â¡Ya comienza la #ConferenciaDePrensa: #Coronavirus #COVID19 de miÃ©rcoles 15  de abril de 2020!\\nAquÃ\\xad la cobertura. ð\\x9f\\x94´']\n",
            " ['The Lovely Lisa Ann Joins The Show LIVE From NYC!! -  \\n\\n   \\n\\n#NFL #MLB #COVID19 #Coronavirus \\n\\nLISTEN \\n']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW8px67_jjsZ"
      },
      "source": [
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tykwrkgnjoYf"
      },
      "source": [
        "scores = []\r\n",
        "# Declare variables for scores\r\n",
        "positive = 0\r\n",
        "negative = 0\r\n",
        "neutral = 0\r\n",
        "compound_list = []\r\n",
        "positive_list = []\r\n",
        "negative_list = []\r\n",
        "neutral_list = []\r\n",
        "labels = []\r\n",
        "\r\n",
        "for i in range(df.shape[0]):\r\n",
        "  compound = analyzer.polarity_scores(df[i])[\"compound\"]\r\n",
        "  pos = analyzer.polarity_scores(df[i])[\"pos\"]\r\n",
        "  neu = analyzer.polarity_scores(df[i])[\"neu\"]\r\n",
        "  neg = analyzer.polarity_scores(df[i])[\"neg\"]\r\n",
        "  if(neg > pos):\r\n",
        "    negative_list.append(df[i])\r\n",
        "    status = \"Negative\"\r\n",
        "    negative+=1\r\n",
        "  elif (pos > neg):\r\n",
        "    positive_list.append(df[i])\r\n",
        "    status = \"Positive\"\r\n",
        "    positive+=1\r\n",
        "  elif (pos == neg):\r\n",
        "    neutral_list.append(df[i])\r\n",
        "    status = \"Neutral\"\r\n",
        "    neutral+=1\r\n",
        "  scores.append({\"Compound\": compound, \"Positive\": pos, \"Negative\": neg, \"Neutral\": neu, \"Status\": status})\r\n",
        "  labels.append(status)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "zHlNGIbAjt6y",
        "outputId": "3a6d5c25-4d8b-4817-b915-a4b668ec0731"
      },
      "source": [
        "df1 = pd.DataFrame(df)\r\n",
        "Y_train = pd.DataFrame.from_dict(scores)\r\n",
        "df1 = df1.join(Y_train)\r\n",
        "df1.head(1000)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>Compound</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Para complementar la higiene de tus manos, el ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PWDs from Tahanang Walang Hagdan get aid amid ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#France à¹à¸à¹à¸£à¸±à¸à¸à¸§à¸²à¸¡à¸à¸¸à¸...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Target ng Department of Health na magkaroon ng...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>La  lanzÃ³ una nueva convocatoria especial par...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Marcos AssunÃ§Ã£o, diretor de Assuntos Parlame...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Parte epidemiolÃ³gico  15/04. Misiones tiene 9...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Pdte.  envia saludo de agradecimiento a dueÃ±...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>A pandemia #COVID19 descortinou o brasileiro i...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Encore un aide-soignant emportÃ© par #COVID19 ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     0  ...   Status\n",
              "0    Para complementar la higiene de tus manos, el ...  ...  Neutral\n",
              "1    PWDs from Tahanang Walang Hagdan get aid amid ...  ...  Neutral\n",
              "2    #France à¹à¸à¹à¸£à¸±à¸à¸à¸§à¸²à¸¡à¸à¸¸à¸...  ...  Neutral\n",
              "3    Target ng Department of Health na magkaroon ng...  ...  Neutral\n",
              "4    La  lanzÃ³ una nueva convocatoria especial par...  ...  Neutral\n",
              "..                                                 ...  ...      ...\n",
              "995  Marcos AssunÃ§Ã£o, diretor de Assuntos Parlame...  ...  Neutral\n",
              "996  Parte epidemiolÃ³gico  15/04. Misiones tiene 9...  ...  Neutral\n",
              "997   Pdte.  envia saludo de agradecimiento a dueÃ±...  ...  Neutral\n",
              "998  A pandemia #COVID19 descortinou o brasileiro i...  ...  Neutral\n",
              "999  Encore un aide-soignant emportÃ© par #COVID19 ...  ...  Neutral\n",
              "\n",
              "[1000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIWbOH2Cjw4v"
      },
      "source": [
        "def percentage(part,whole):\r\n",
        "  return 100 * float(part)/float(whole)\r\n",
        "\r\n",
        "positive = percentage(positive, noOfTweet)\r\n",
        "negative = percentage(negative, noOfTweet)\r\n",
        "neutral = percentage(neutral, noOfTweet)\r\n",
        "positive = format(positive, '.1f')\r\n",
        "negative = format(negative, '.1f')\r\n",
        "neutral = format(neutral, '.1f')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k79LhOj1kj4Z",
        "outputId": "687ba8a4-40eb-4d4f-f299-a0b60fbc3fa9"
      },
      "source": [
        "#Number of Tweets (Total, Positive, Negative, Neutral)\r\n",
        "tweet_list = pd.DataFrame(df1)\r\n",
        "neutral_list = pd.DataFrame(neutral_list)\r\n",
        "negative_list = pd.DataFrame(negative_list)\r\n",
        "positive_list = pd.DataFrame(positive_list)\r\n",
        "print(\"total number:\",len(tweet_list))\r\n",
        "print(\"positive number:\",len(positive_list))\r\n",
        "print(\"negative number:\", len(negative_list))\r\n",
        "print(\"neutral number:\",len(neutral_list))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total number:  298687\n",
            "positive number:  101217\n",
            "negative number:  78041\n",
            "neutral number:  119429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPoQ2eM9pqbR",
        "outputId": "b535f24c-8111-41a4-fb2b-c911ce5b10a5"
      },
      "source": [
        "df_final = df1[[0,\"Status\"]].copy()\r\n",
        "#print(df_final)\r\n",
        "df_final = df_final[df_final.Status != \"Neutral\"]\r\n",
        "df_final[0] = df_final[0].apply(lambda x: x.lower())\r\n",
        "df_final[0] = df_final[0].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\r\n",
        "\r\n",
        "print(df_final[ df_final['Status'] == 'Positive'].size)\r\n",
        "print(df_final[df_final['Status'] == 'Negative'].size)\r\n",
        "\r\n",
        "for idx,row in df1.iterrows():\r\n",
        "    row[0] = row[0].replace('rt',' ')\r\n",
        "X = df_final[0]\r\n",
        "#print(X)\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "202434\n",
            "156082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xBVJ74sp2mU",
        "outputId": "cdc5a697-9887-497b-bf8e-108e42d74528"
      },
      "source": [
        "import sklearn.model_selection as model_selection\r\n",
        "Y = df_final['Status']\r\n",
        "#print(Y)\r\n",
        "#print(type(Y))\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,train_size=0.80, test_size=0.20, random_state=0)\r\n",
        "\"\"\"print(X_train)\r\n",
        "print(Y_train)\"\"\"\r\n",
        "print(X_train.shape,Y_train.shape)\r\n",
        "print(X_test.shape,Y_test.shape)\r\n",
        "#print(type(X_train))\r\n",
        "\"\"\"x_train = pd.DataFrame(X_train)\r\n",
        "y_train = pd.DataFrame(Y_train)\r\n",
        "x_test = pd.DataFrame(X_test)\"\"\"\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer \r\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,recall_score,precision_score\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "\r\n",
        "cv = CountVectorizer()\r\n",
        "x_train = cv.fit_transform(X_train)\r\n",
        "y_train = Y_train\r\n",
        "x_test = cv.transform(X_test)\r\n",
        "y_test = Y_test\r\n",
        "#print(x_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(143406,) (143406,)\n",
            "(35852,) (35852,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQJr9BYoAiU5",
        "outputId": "3249c408-eab1-417f-c6db-296c0385e866"
      },
      "source": [
        "nb = MultinomialNB()\r\n",
        "nb.fit(x_train,y_train)\r\n",
        "nb_predict=nb.predict(x_test)\r\n",
        "#print(nb_predict)\r\n",
        "nb_report = accuracy_score(y_test,nb_predict)\r\n",
        "print('Accuracy:',nb_report)\r\n",
        "#print(y_test[1:20])\r\n",
        "#print(nb_predict[1:20])\r\n",
        "\r\n",
        "nb_report2 = precision_score(y_test,nb_predict,pos_label='Positive',average='binary')\r\n",
        "print('Precision:',nb_report2)\r\n",
        "\r\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8148778310833427\n",
            "Precision: 0.7877888488446046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u310i4i3K1Y6",
        "outputId": "b24416bd-4703-4e26-f5b8-f55265c5c041"
      },
      "source": [
        "twt1 = ['MFirst phase of #COVAXINVaccine was completed at PGIMS Rohtak now, Second phase of #HumanTrials of indigenously']\r\n",
        "twt2 = ['Chief Minister @NitishKumar has ordered immediate antigen testing of the flood victims taking shelter in the governance']\r\n",
        "twt3 = ['Help slow the spread of #COVID19 and identify at risk cases sooner by self-reporting your symptoms daily, even if']\r\n",
        "twt = cv.transform(twt3)\r\n",
        "print(nb.predict(twt))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Positive']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}